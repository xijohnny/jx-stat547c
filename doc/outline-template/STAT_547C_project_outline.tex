%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for STAT 547C Final Project Outline
% Author: Ben Bloem-Reddy <benbr@stat.ubc.ca>
% Date: Oct. 17, 2019
% Acknowledgments: ETH, Peter Orbanz, John Cunningham
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[]{STAT_547C}
\usepackage{STAT_547C}
% NOTE: change the name and email address to your name in STAT_547C.sty

\usepackage{booktabs}
\usepackage{amsmath,amsthm,amssymb,amsfonts}

\usepackage[sorting=none,backend=biber,bibstyle=alphabetic,citestyle=alphabetic,giveninits=true,natbib=true]{biblatex}
\bibliography{../../ref/STAT_547C.bib} % add the title and location of your bibliography file

\begin{document}

% NOTE: You will replace the title below with your actual Title.
\makeGenericHeader{A Variational Bernstein-von Mises Result}{Project Outline}
\vspace{-2cm}


%%%%%%%%%%%%%%%%%%%
\section{Background}

The traditional Bernstein-von Mises theorem establishes some properties of the Bayesian posterior distribution when the true model parameters are assumed to be constant. It roughly states that, under some regularity conditions on the model and prior,  the posterior distribution converges to a Normal distribution centered at the true parameter in total variation. The variational Bernstein von-Mises theorem states similar results when the posterior is replaced with a best approximation (in terms of a minimum divergence) from a parametric family. Of interest are the conditions, and model specifications under which the variational Bernstein-von Mises result holds. This result can support inference in complex models such as Bayesian neural networks, where variational approximations are necessary for model fitting. Beyond this, it is also informative to understand the robustness of these results for variational Bayes, and when it might produce undesirable estimators for inference. 

%%%%%%%%%%%%%%%%%%%
\section{Technical aspects}

Measure-theoretic probability is the setting of the project and is the core technical tool that will be used in exposition. The project will require knowledge of asymptotic theory (particularly stochastic convergence), as the main result only holds in the large sample limit. General knowledge of Bayesian inference and model building will be needed. Since computing the variational posterior requires taking a minimum, tools from mathematical optimization will be needed.


%%%%%%%%%%%%%%%%%%%
\section{Literature}

The key references for this project are: 

\begin{itemize}
  \item Main reference for result: \cite{Wang:2019:VBVM}
  \item References for proof techniques: \cite{Asymptotics:2000} \cite{kleijn2012} \cite{Lu:2017}
  \item References for inference with (mean-field) variational Bayes: \cite{GiordanoJMLR}
  \item References for extensions of variational objectives: \cite{f2020} \cite{renyi2016} 
\end{itemize}


%%%%%%%%%%%%%%%%%%%
\section{Plan}

I will carry out this project with the following sequence of steps: 
\begin{enumerate}
  \item Review of proof techniques Bernstein-von Mises type results for exact Bayesian inference. 
  \item Careful study of the connections in proof structure between exact and variational Bernstein von-Mises. Specifically, how do the assumptions required change when the posterior is replaced with a variational approximation?
  \item Reproduce the proof of preliminary lemmas and main result, with commentary.
  \item Explore possible extensions of the current result, specifically extending beyond the standard mean-field model and Kullback-Leibler divergence combination. 
  \item Study the limitations in application of the current result. Possibly: how does the variance estimation affect inference in application?

\end{enumerate}


%%%%%%%%%%%%%%%%%%%
\section{Why I'm interested in this topic}

Variational inference is of personal interest to me from a research standpoint. Much like Bayesian inference itself, variational Bayes provides a simple framework that may be difficult to analyze rigorously at any level of generality. As is mentioned in many of the relevant references, the theoretical properties of variational Bayes approximations are not yet well understood. Studying the variational Bernstein von-Mises theorem provides insight into one of the most prominent theoretical developments from a traditional, mathematical statistics point of view. I'm hoping that I can begin to see some of the connections between variational Bayes, exact Bayesian inference, and frequentist inference by understanding the ideas behind this proof. 

%%%%%%%%%%%%%%%%%%%
\printbibliography

\end{document}

